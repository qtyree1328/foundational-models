# LEOM Knowledge Base Updates: 2024-2026 Research

**Date:** 2026-02-14  
**Purpose:** Document latest developments in Large Earth Observation Models for GeoFM Dashboard updates

---

## üöÄ BREAKING: 2026 Developments

### **Nature Communications Earth & Environment (January 2026)**
**Paper:** "On the foundations of Earth foundation models" `arXiv:TBD`
**Venue:** Nature Communications Earth & Environment (high-impact journal)

**11 Critical Features for Ideal Earth FMs:**
- **Geolocation and scale awareness** - Understanding spatial context and resolution differences
- **Multisensor integration** - Fusion of optical, SAR, hyperspectral, and other modalities
- **Carbon-efficient operation** - Sustainable training and inference for climate applications
- **Physical consistency** - Adherence to Earth system physics and conservation laws
- **Temporal dynamics** - Understanding seasonal, annual, and long-term changes
- **Transferability** - Adaptation across geographic regions and climate zones
- **Uncertainty quantification** - Confidence estimation for scientific applications
- **Interpretability** - Understanding model decisions for scientific validation
- **Scalability** - Handling petabyte-scale datasets efficiently
- **Real-time capability** - Supporting operational monitoring and early warning
- **Multi-resolution support** - Working across scales from local to global

**Key Insight:** *"FMs offer a promising pathway forward by learning generalizable feature representations from large-scale unlabeled data... supporting a scalable AI infrastructure for Earth monitoring, forecasting, and decision-making"*

### **Scaling Laws for GFMs: PhilEO Bench Study (January 2026)**
**Paper:** "Scaling Laws for Geospatial Foundation Models" `arXiv:2506.14765`
**Authors:** Nikolaos Dionelis et al.

**Massive Scale Training Experiments:**
- **PhilEO Globe:** 0.5TB (small-scale)
- **FastTOM:** 2TB (medium-scale, newly introduced)
- **MajorTOM:** 23TB (large-scale)

**Architecture Performance Insights:**
- **CNN-based models (Geo-Aware U-Net):** Remain highly competitive in low-shot settings; 200M parameter model outperforms larger architectures on regression tasks
- **ViT-UPerNet (Transformer):** Achieves best performance when scaling to multi-terabyte datasets, particularly for semantic segmentation on 23TB MajorTOM
- **Mamba (State-Space Models):** Show efficiency advantages but require further large-scale pretraining to match CNNs/ViTs

**Critical Finding:** Dataset size matters more than architecture for downstream performance at scale. 23TB training enables substantial improvement over smaller datasets across all architectures.

### **REOBench: First Comprehensive Robustness Benchmark (2025-2026)**
**Paper:** "REOBench: Benchmarking Robustness of Earth Observation Foundation Models" `arXiv:2505.16793`
**Authors:** Xiang Li, Xiao Xiang Zhu, et al.

**Benchmark Coverage:**
- **6 Tasks:** Land cover, building segmentation, road mapping, crop classification, change detection, object detection
- **12 Corruption Types:** Weather (fog, rain, snow), sensor noise, compression artifacts, geometric perturbations
- **Key Finding:** Current LEOMs show significant vulnerability to real-world corruptions

**Implications for Production Deployment:**
- LEOMs need robustness improvements before operational use
- Weather and sensor-specific training crucial for reliable performance
- Gap between research benchmarks and real-world reliability

### **Remote Sensing Foundation Models Survey (June 2025)**
**Paper:** "Foundation Models for Remote Sensing and Earth Observation: A Survey" `arXiv:2410.16602`
**Authors:** Aoran Xiao et al.
**Venue:** IEEE Geoscience and Remote Sensing Magazine (accepted)

**Comprehensive Classification:**
- **Visual Foundation Models (VFMs):** Clay, Prithvi, SkySense
- **Vision-Language Models (VLMs):** RemoteCLIP, GeoChat, ChatEarthNet
- **Large Language Models (LLMs):** Adapted for geospatial reasoning
- **Multimodal Architectures:** SAR+optical, hyperspectral+RGB fusion

**GitHub Repository:** [awesome-RSFMs](https://github.com/xiaoaoran/awesome-RSFMs) - Continuously updated model catalog

---

## Major 2024-2025 Developments

### üöÄ **NASA/IBM Prithvi Updates (February 2025)**

**Prithvi Geospatial Enhanced (Current):**
- **Global Data Expansion:** Now includes worldwide HLS satellite imagery (vs. previous CONUS-only)
- **Improved Quality Controls:** Strict cloud filtering and urban area emphasis for better global representation
- **Enhanced Applications:** Multi-temporal cloud gap imputation, multi-temporal crop segmentation, flood mapping, wildfire scar mapping
- **Performance:** Rigorous testing across broader range of downstream use cases
- **Quote:** *"We've embedded NASA's scientific expertise directly into these foundation models, enabling them to quickly translate petabytes of data into actionable insights"* - Kevin Murphy, NASA Chief Science Data Officer

**Prithvi-EO-2.0 (December 2024):**
- **Scale:** 300M and 600M parameter variants
- **Performance:** 8% improvement over v1.0 across GEO-Bench tasks
- **Architecture:** Multi-temporal capabilities with enhanced temporal fusion
- **Paper:** arXiv:2412.02732

### üéØ **Google Research Developments (2024-2025)**

**Remote Sensing Foundation Models (New):**
- **Architecture:** Based on masked autoencoders, SigLIP, MaMMUT, OWL-ViT adapted for remote sensing
- **Training:** High-resolution satellite and aerial images with text descriptions and bounding box annotations
- **Capabilities:** Rich embeddings, fine-tuning for specific tasks, natural language interface
- **Applications:** Building/road mapping, post-disaster damage assessment, infrastructure location
- **Partnership:** Trusted tester program with WPP, Airbus, Maxar, Planet Labs

**Geospatial Reasoning Framework (2024):**
- **Purpose:** Agentic workflows combining foundation models with generative AI
- **Integration:** Gemini orchestrating inference across Google's models and user data
- **Components:** LangGraph agent on Vertex AI, Earth Engine/BigQuery/Maps Platform tools
- **Use Case:** Post-hurricane damage assessment with WeatherNext AI weather forecasting

**AlphaEarth Foundations (December 2025):**
- **Availability:** Now on Google Cloud Storage for production use
- **Paper:** arXiv:2507.22291 - "AlphaEarth Foundations: An embedding field model for accurate and efficient global mapping from sparse label data"

### üèõÔ∏è **Academic & Industry Advances**

**SkySense++ (Nature Machine Intelligence, 2025):**
- **Venue:** Nature Machine Intelligence (high-impact journal)
- **Enhancement:** Follow-up to SkySense with improved semantic understanding
- **Focus:** Multi-modal remote sensing foundation model for universal interpretation

**Key New Models from GitHub Survey:**

1. **AnySat (CVPR 2025)** - Earth Observation model for any resolutions, scales, and modalities
2. **Panopticon (CVPR 2025)** - Any-sensor foundation model advancing multi-sensor capabilities  
3. **TerraFM (2025)** - Scalable foundation model for unified multisensor Earth observation
4. **SkySense V2 (ICCV 2025)** - Unified foundation model for multi-modal remote sensing
5. **Galileo (ICML 2025)** - Learning global and local features in pretrained remote sensing models
6. **RoMA (2025)** - Scaling up Mamba-based foundation models for remote sensing

**OReole-FM (SIGSPATIAL 2024):**
- **Scale:** Billion-parameter models for high-resolution satellite imagery
- **Focus:** Emergent abilities research in geospatial domain
- **Paper:** arXiv:2410.19965

### üìä **Benchmarking Evolution**

**New Benchmark Suites (2025):**
- **PANGAEA:** Global and inclusive benchmark for geospatial foundation models
- **GEOBench-VLM:** Vision-language model evaluation for geospatial tasks  
- **XLRS-Bench (CVPR 2025):** Extremely large ultra-high-resolution remote sensing imagery benchmarks
- **Copernicus-Bench:** Unified evaluation for European Earth observation data

### üí∞ **Industry & Funding**

**LGND Infrastructure Company:**
- **Funding:** $9M seed round (July 2025) led by Javelin Venture Partners
- **Founders:** Dan Hammer & Bruno S√°nchez-Andrade Nu√±o (Clay creators)
- **Focus:** Infrastructure layer between LEOMs and applications
- **Mission:** Democratizing access to geo-embeddings for developers

**NASA ROSES-2025:**
- **Budget:** $700M+ initiative for user-centered applications with Large Earth Foundation Models
- **Focus:** Prithvi-EO applications and community adoption

---

## Key Terminology Updates

### "LEOM" Adoption
- **Large Earth Observation Models** is now the standard industry term (replacing "Geospatial Foundation Models")
- **Source:** LGND's academic publications and industry adoption
- **Usage:** Preferred in technical documentation and research papers

### Geo-Embeddings vs Pixel Classification
- **Paradigm Shift:** From pixel-level classification to geo-embeddings
- **Analogy:** Similar to NLP evolution from keywords to language model embeddings
- **Impact:** Enables more generalizable and transferable representations

---

## Updated Model Specifications

### **Prithvi Updates:**
- **Current Version:** Prithvi Geospatial Enhanced + Prithvi-EO-2.0
- **Global Coverage:** ‚úÖ Worldwide (previously CONUS-only)
- **Parameter Options:** 100M (v1) + 300M/600M (v2.0)
- **Performance Improvement:** +8% on GEO-Bench (v2.0 over v1.0)

### **Clay Updates:**
- **Status:** Active development with Development Seed
- **Enhanced:** Multi-sensor capabilities
- **Community:** Growing adoption through Clay Foundation

### **Google Models:**
- **AlphaEarth:** Production-ready on Cloud Storage
- **Remote Sensing FMs:** Trusted tester program active
- **Geospatial Reasoning:** Agentic framework available

---

## Research Gaps Identified

1. **Limited Real-world Validation:** Most models lack extensive real-world deployment data
2. **Cross-sensor Generalization:** Need better evaluation across different satellite platforms
3. **Temporal Modeling:** Multi-temporal capabilities remain underdeveloped
4. **Label Efficiency:** Foundation models show promise but need more systematic studies

---

## Implementation Priority

### High Priority Updates:
1. Update Prithvi specifications with global coverage and v2.0 details
2. Add Google Remote Sensing Foundation Models section
3. Update terminology from "Geospatial FM" to "LEOM" throughout
4. Add new 2025 models (AnySat, Panopticon, TerraFM)

### Medium Priority:
1. Expand benchmarking section with new evaluation suites
2. Add industry partnership details (Airbus, Maxar, Planet Labs)
3. Update funding/investment landscape

### Research Citations to Add:
- NASA Science (Feb 2026): Expanded AI Model with Global Data
- Google Research Blog: Geospatial Reasoning framework
- GitHub Awesome-Remote-Sensing-Foundation-Models (comprehensive model list)
- Nature Machine Intelligence: SkySense++
- Multiple CVPR/ICCV 2025 papers

---

**Next Steps:**
1. Update ModelGallery.tsx with new models and specifications
2. Revise technical content with latest benchmarks and capabilities
3. Update terminology throughout the dashboard
4. Add references and citations for credibility